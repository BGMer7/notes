# Message Queue

### 六个场景对比适合RabbitMQ还是Kafka

#### 消息的顺序

有这样一个需求：当订单状态变化的时候，把订单状态变化的消息发送给所有关心订单变化的系统。

1. 订单会有创建成功、待付款、已支付、已发货的状态，状态之间是单向流动的。

   <img src="https://pic1.zhimg.com/v2-9ff9beb78cfea1f2d402abaeb83d19f6_r.jpg?source=1940ef5c" alt="img" style="zoom:50%;" />

2. 更新了状态之后，现在我们把订单状态变化消息要发送给所有关心订单状态的系统上去，实现方式就是用消息队列。

   <img src="https://pic1.zhimg.com/v2-98d5385101e2922e302141b53186b904_r.jpg?source=1940ef5c" alt="img" style="zoom:50%;" />

3. 在这种业务下，我们最需要的其实是两点：

   1. 消息的顺序：对于同一笔订单而言，状态的变化都是有严格的先后顺序的。
   2. 吞吐量：像订单的业务，我们自然希望越多越好，订单越多，吞吐量就越多。

4. 在这种场景下，RabbitMQ的做法是，**首先，对于发消息，并广播给多个消费者这种情况，RabbitMQ 会为每个消费者建立一个对应的队列。也就是说，如果有 10 个消费者，RabbitMQ 会建立 10 个对应的队列。然后，当一条消息被发出后，RabbitMQ 会把这条消息复制 10 份放到这 10 个队列里。**<img src="https://pic1.zhimg.com/v2-6abd470247cd617f59a7099d513aa602_r.jpg?source=1940ef5c" alt="img" style="zoom:50%;" />

   当 RabbitMQ 把消息放入到对应的队列后，我们紧接着面临的问题就是，我们应该在系统内部启动多少线程去从消息队列中获取消息。RabbitMQ 有这么个特性，它在官方文档就声明了自己是不保证多线程消费同一个队列的消息，一定保证顺序的。而不保证的原因，是因为多线程时，当一个线程消费消息报错的时候，RabbitMQ 会把消费失败的消息再入队，此时就可能出现乱序的情况。<img src="https://pic1.zhimg.com/v2-f6e27271afcd729fc494e8fc7debd89e_r.jpg?source=1940ef5c" alt="img" style="zoom: 67%;" />

   T0 时刻，队列中有四条消息 A1、B1、B2、A2。其中 A1、A2 表示订单 A 的两个状态：待付款、已付款。B1、B2 也同理，是订单 B 的待付款、已付款。

   到了 T1 时刻，消息 A1 被线程 1 收到，消息 B1 被线程 2 收到。此时，一切都还正常。

   到了 T3 时刻，B1 消费出错了，同时呢，由于线程 1 处理速度快，又从消息队列中获取到了 B2。此时，问题开始出现。

   到了 T4 时刻，由于 RabbitMQ 线程消费出错，可以把消息重新入队的特性，此时 B1 会被重新放到队列头部。所以，如果不凑巧，线程 1 获取到了 B1，就出现了乱序情况，B2 状态明明是 B1 的后续状态，却被提前处理了。

   所以，可以看到了，这个场景用 RabbitMQ，出现了三个问题：

   1. 为了实现发布订阅功能，从而使用的消息复制，会降低性能并耗费更多资源
   2. 多个消费者无法严格保证消息顺序
   3. 大量的订单集中在一个队列，吞吐量受到了限制

5. 在这种场景下，Kafka在这几点的场景下会比RabbitMQ好很多。

   1. 首先，Kafka的发布订阅并不是通过复制消息实现的。Kafka的发布订阅是消费者直接去获取被Kafka保存在日志文件中的消息，所以无论多少消费者，都是通过主动的方式去获取消息在文件中的位置。
   2. 其次，Kafka不会出现消费者出错之后，将消息重新入队的问题。
   3. 最后，Kafka 可以对订单进行分区，把不同订单分到多个分区中保存，这样，吞吐量能更好。

   所以在这种场景下，Kafka要更加合适。



#### 消息的匹配

假设存在一个营销系统，这套系统中有一个很显著的特点，就是非常复杂非常灵活的匹配规则。

比如，要根据推广内容去匹配不同的方式做宣传。又比如，要根据不同的活动去匹配不同的渠道去做分发。在这套系统中，存在很多种匹配规则。

<img src="https://pic1.zhimg.com/v2-d467d9e2759cc49fcb1d09cab3ad6fe3_r.jpg?source=1940ef5c" alt="img" style="zoom:50%;" />

首先，先看看 RabbitMQ，你会发现 RabbitMQ 是允许在消息中添加 routing_key 或者自定义消息头，然后通过一些特殊的 Exchange，很简单的就实现了消息匹配分发。开发几乎不用成本。

而 Kafka 呢？如果你要实现消息匹配，开发成本高多了。

首先，通过简单的配置去自动匹配和分发到合适的消费者端这件事是不可能的。

其次，消费者端必须先把所有消息不管需要不需要，都取出来。然后，再根据业务需求，自己去实现各种精准和模糊匹配。可能因为过度的复杂性，还要引入规则引擎。

所以在这种场景下，使用Kafka比RabbitMQ要复杂很多。





#### 消息的超时

在电商体系中，有一个很重要的需求是：下单十五分钟之后是否完成了支付，如果没有支付就取消订单，释放资源。

首先解释一下为什么这么个定时任务需要用到消息队列。

在普通的SOA或者微服务架构中，可能就直接一个定时任务就可以结束，但是在微服务架构中，很多的服务都需要获得这个支付结果的状态。如果每一个服务都要单独实现一套自己的定时逻辑，设计的复杂度会大很多。

在这种场景中，我们往往会做一层抽象，把要执行的任务封装成消息，当时间到了，直接将消息丢尽消息队列中，消息的订阅者收到消息之后，可以直接执行这个消息。**这种希望把消息延迟一会再执行的场景叫做延迟队列。**

对于延迟队列这种场景，我们就会在创建订单的时候，同时将一个包含了执行任务信息的消息加到延迟队列中，指定15分钟之后，订阅了这个队列的各个消费者可以收到这个消息，随后各个消费者所在的系统就可以执行相关的检查订单的任务了。

![img](https://pic1.zhimg.com/v2-4737535155eb366b7f91f8d8ef85183c_r.jpg?source=1940ef5c)

RabbitMQ在这种情况中的分析：

1. RabbitMQ首先自带计时。消息中有一个TTL字段，这个字段用于标记该消息在队列中存放的时间，如果超过TTL会被移动到死信队列。所以，延迟队列 RabbitMQ 最简单的实现方式就是设置 TTL，然后一个消费者去监听死信队列，当消息超时了，监听死信队列的消费者就收到消息了。

2. 但是假设队列中有多条信息，并且过期时间不相同，

   > 例如：我们先往队列放入一条过期时间是 10 秒的 A 消息，再放入一条过期时间是 5 秒的 B 消息。 那么问题来了，B 消息会先于 A 消息进入死信队列吗？
   >
   > 答案是否定的。B 消息会优先遵守队列的先进先出规则，在 A 消息过期后，和其一起进入死信队列被消费者消费。
   >
   > 在 RabbitMQ 的 3.5.8 版本以后，官方推荐的 rabbitmq delayed message exchange 插件可以解决这个问题。
   >
   > - 用了这个插件，我们在发送消息的时候，把消息发往一个特殊的 Exchange。
   > - 同时，在消息头里指定要延迟的时间。
   > - 收到消息的 Exchange 并不会立即把消息放到队列里，而是在消息延迟时间到达后，才会把消息放入。

<img src="https://pic1.zhimg.com/v2-3386e85e7dddbeeaf4ad80452fc55d25_r.jpg?source=1940ef5c" alt="img" style="zoom:50%;" />

Kafka本身没有自带延迟队列，自定义实现延迟队列很麻烦。



#### 消息的保持

涉及到消息持久化的时候，基本都是Kafka更占优势，

在微服务里，事件溯源是经常用到的。如果想用消息队列实现，一般是把事件当成消息，依次发送到消息队列中。

事件溯源有个最经典的场景，就是事件的重放。简单来讲就是把系统中某段时间发生的事件依次取出来再处理。而且，根据业务场景不同，这些事件重放很可能不是一次，更可能是重复 N 次。

假设，我们现在需要一批在线事件重放，去排查一些问题。

**RabbitMQ 此时就真的不行了，因为消息被人取出来就被删除了**。想再次被重复消费？对不起。

**而 Kafka 呢，消息会被持久化一个专门的日志文件里**。不会因为被消费了就被删除。

所以，对消息不离不弃的 Kafka 相对用过就抛的 RabbitMQ，请选择 Kafka。



#### 消息的错误处理

很多时候，在做记录数据相关业务的时候，Kafka 一般是不二选择。不过，有时候在记录数据吞吐量不大时，我自己倒是更喜欢用 RabbitMQ。

原因就是 Kafka 有一个我很不喜欢的[设计原则](https://www.zhihu.com/search?q=设计原则&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2335229719})：

当单个分区中的消息一旦出现消费失败，就只能停止而不是跳过这条失败的消息继续消费后面的消息。即不允许消息空洞。

只要消息出现失败，不管是 Kafka 自身消息格式的损坏，还是消费者处理出现异常，是不允许跳过消费失败的消息继续往后消费的。

所以，在**数据统计不要求十分精确**的场景下选了 Kafka，一旦出现了消息消费问题，就会发生项目不可用的情况。这真是徒增烦恼。

而 RabbitMQ 呢，它由于会在消息出问题或者消费错误的时候，可以重新入队或者移动消息到死信队列，继续消费后面的，会省心很多。

坏消息就像群众中的坏蛋那样，Kafka 处理这种坏蛋太过残暴，非得把坏蛋揪出来不行。相对来说，RabbitMQ 就温柔多了，群众是群众，坏蛋是坏蛋，分开处理嘛。



#### 消息的吞吐量

**Kafka 是每秒几十万条消息吞吐，而 RabbitMQ 的吞吐量是每秒几万条消息，Kafka的吞吐量更大。**







## RabbitMQ架构

[RabbitMQ](https://so.csdn.net/so/search?q=RabbitMQ&spm=1001.2101.3001.7020)是采用Erlang语言实现AMQP（Advanced Message Queuing Protocol,高级消息队列协议）的消息中间件。































## Kafka

**Kafka** 是一个消息系统，原本开发自 LinkedIn，用作 LinkedIn 的活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础。现在它已被作为多种类型的数据管道和消息系统使用。

### **Kafka 简介**

Kafka 是一种分布式的，基于发布 / 订阅的消息系统。主要设计目标如下：

- 以时间复杂度为 O(1) 的方式提供消息持久化能力，即使对 TB 级以上数据也能保证常数时间复杂度的访问性能。
- 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条以上消息的传输。
- 支持 Kafka Server 间的消息分区，及分布式消费，同时保证每个 Partition 内的消息顺序传输。
- 同时支持离线数据处理和实时数据处理。
- Scale out：支持在线水平扩展。



### Kafka 基础概念

#### 概念一：Producer/Consumer

对于 Kafka 来说客户端有两种基本类型：**生产者（Producer）**和**消费者（Consumer）**。除此之外，还有用来做数据集成的 Kafka Connect API 和流式处理的 Kafka Streams 等高阶客户端，但这些高阶客户端底层仍然是生产者和消费者API，它们只不过是在上层做了封装。

这很容易理解，生产者（也称为发布者）创建消息，而消费者（也称为订阅者）负责消费or读取消息。



#### 概念二：Topic/Partition

在 Kafka 中，消息以**主题（Topic）**来分类，每一个主题都对应一个「消息队列」，这有点儿类似于数据库中的表。但是如果我们把所有同类的消息都塞入到一个“中心”队列中，势必缺少可伸缩性，无论是生产者/消费者数目的增加，还是消息数量的增加，都可能耗尽系统的性能或存储。

我们使用一个生活中的例子来说明：现在 A 城市生产的某商品需要运输到 B 城市，走的是公路，那么单通道的高速公路不论是在「A 城市商品增多」还是「现在 C 城市也要往 B 城市运输东西」这样的情况下都会出现「吞吐量不足」的问题。所以我们现在引入**分区（Partition）**的概念，类似“允许多修几条道”的方式对我们的主题完成了水平扩展。



#### 概念三：Broker/Cluster

一个 Kafka 服务器也称为 Broker，它接受生产者发送的消息并存入磁盘；Broker  同时服务消费者拉取分区消息的请求，返回目前已经提交的消息。使用特定的机器硬件，一个 Broker  每秒可以处理成千上万的分区和百万量级的消息。（现在动不动就百万量级..我特地去查了一把，好像确实集群的情况下吞吐量挺高的..摁..）

若干个 Broker 组成一个集群（Cluster），其中集群内某个 Broker 会成为集群控制器（Cluster  Controller），它负责管理集群，包括分配分区到 Broker、监控 Broker 故障等。在集群内，一个分区由一个 Broker  负责，这个 Broker 也称为这个分区的 Leader；当然一个分区可以被复制到多个 Broker 上来实现冗余，这样当存在 Broker  故障时可以将其分区重新分配到其他 Broker 来负责。下图是一个样例：![img](https://pic2.zhimg.com/v2-9c8de1bed82a54799c4ef2cbfeedab61_r.jpg)

**Kafka 的一个关键性质是日志保留（retention）**，我们可以配置主题的消息保留策略，譬如只保留一段时间的日志或者只保留特定大小的日志。当超过这些限制时，老的消息会被删除。我们也可以针对某个主题单独设置消息过期策略，这样对于不同应用可以实现个性化。



#### 概念四：多集群

随着业务的发展，我们往往需要多集群，通常处于下面几个原因：

- 基于数据的隔离；
- 基于安全的隔离；
- 多数据中心（容灾）

当构建多个数据中心时，往往需要实现消息互通。举个例子，假如用户修改了个人资料，那么后续的请求无论被哪个数据中心处理，这个更新需要反映出来。又或者，多个数据中心的数据需要汇总到一个总控中心来做数据分析。

上面说的分区复制冗余机制只适用于同一个 Kafka 集群内部，对于多个 Kafka 集群消息同步可以使用 Kafka 提供的 MirrorMaker  工具。本质上来说，MirrorMaker 只是一个 Kafka  消费者和生产者，并使用一个队列连接起来而已。它从一个集群中消费消息，然后往另一个集群生产消息。



















